edge_attr (torch.Size([24000, 10])): tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]])
SLURM ID: 0
Start Pre-Training
No pre-trained checkpoint found.

TRAIN.PY
i_batch: 0
train_be (24000): tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')
train_bs (2000): tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')
train_bt (12): tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


EDGE MODEL FORWARD
src (torch.Size([24000])): tensor([   0,    0,    0,  ..., 1999, 1999, 1999], device='cuda:0')
tgt (torch.Size([24000])): tensor([0, 1, 2,  ..., 7, 8, 9], device='cuda:0')
x_s (torch.Size([2000, 10])): tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')
x_t (torch.Size([12, 2])): tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.]], device='cuda:0')
edge_attr (torch.Size([24000, 10])): tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')
u (torch.Size([1, 10])): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
h (torch.Size([24000, 32]))
x_s[src] (torch.Size([24000, 10]))
x_t[tgt] (torch.Size([24000, 2]))
edge_attr (torch.Size([24000, 10]))
u[batch_e] torch.Size([24000, 10])

EDGE MODEL FORWARD
src (torch.Size([24000])): tensor([   0,    0,    0,  ..., 1999, 1999, 1999], device='cuda:0')
tgt (torch.Size([24000])): tensor([0, 1, 2,  ..., 7, 8, 9], device='cuda:0')
x_s (torch.Size([2000, 10])): tensor([[ 4.7122e-05,  1.1780e-05, -1.1780e-06,  ..., -4.7122e-06,
          4.7122e-05,  9.4243e-06],
        [ 4.7122e-05,  1.1780e-05, -1.1780e-06,  ..., -4.7122e-06,
          4.7122e-05,  9.4243e-06],
        [ 4.7122e-05,  1.1780e-05, -1.1780e-06,  ..., -4.7122e-06,
          4.7122e-05,  9.4243e-06],
        ...,
        [ 4.7122e-05,  1.1780e-05, -1.1780e-06,  ..., -4.7122e-06,
          4.7122e-05,  9.4243e-06],
        [ 4.7122e-05,  1.1780e-05, -1.1780e-06,  ..., -4.7122e-06,
          4.7122e-05,  9.4243e-06],
        [ 4.7122e-05,  1.1780e-05, -1.1780e-06,  ..., -4.7122e-06,
          4.7122e-05,  9.4243e-06]], device='cuda:0',
       grad_fn=<NativeBatchNormBackward0>)
x_t (torch.Size([12, 2])): tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.]], device='cuda:0', grad_fn=<NativeBatchNormBackward0>)
edge_attr (torch.Size([24000, 10])): tensor([[-1.4136e-05,  2.3561e-06,  2.3561e-06,  ...,  0.0000e+00,
         -4.7122e-06,  0.0000e+00],
        [-1.4136e-05,  2.3561e-06,  2.3561e-06,  ...,  0.0000e+00,
         -4.7122e-06,  0.0000e+00],
        [-1.4136e-05,  2.3561e-06,  2.3561e-06,  ...,  0.0000e+00,
         -4.7122e-06,  0.0000e+00],
        ...,
        [-1.4136e-05,  2.3561e-06,  2.3561e-06,  ...,  0.0000e+00,
         -4.7122e-06,  0.0000e+00],
        [-1.4136e-05,  2.3561e-06,  2.3561e-06,  ...,  0.0000e+00,
         -4.7122e-06,  0.0000e+00],
        [-1.4136e-05,  2.3561e-06,  2.3561e-06,  ...,  0.0000e+00,
         -4.7122e-06,  0.0000e+00]], device='cuda:0',
       grad_fn=<NativeBatchNormBackward0>)
u (torch.Size([1, 10])): tensor([[ -7.6861,  -7.8733,   2.9180,   0.0421, -15.4044,  -6.6698,   3.4797,
          -8.5611,  -0.2612,   6.1192]], device='cuda:0',
       grad_fn=<AddmmBackward0>)
h (torch.Size([24000, 32]))
x_s[src] (torch.Size([24000, 10]))
x_t[tgt] (torch.Size([24000, 2]))
edge_attr (torch.Size([24000, 10]))
u[batch_e] torch.Size([24000, 10])

EDGE MODEL FORWARD
src (torch.Size([24000])): tensor([   0,    0,    0,  ..., 1999, 1999, 1999], device='cuda:0')
tgt (torch.Size([24000])): tensor([0, 1, 2,  ..., 7, 8, 9], device='cuda:0')
x_s (torch.Size([2000, 10])): tensor([[-9.4243e-06,  3.7697e-05,  3.7697e-05,  ...,  1.8849e-05,
         -9.4243e-06, -1.1309e-04],
        [-9.4243e-06,  3.7697e-05,  3.7697e-05,  ...,  1.8849e-05,
         -9.4243e-06, -1.1309e-04],
        [-9.4243e-06,  3.7697e-05,  3.7697e-05,  ...,  1.8849e-05,
         -9.4243e-06, -1.1309e-04],
        ...,
        [-9.4243e-06,  3.7697e-05,  3.7697e-05,  ...,  1.8849e-05,
         -9.4243e-06, -1.1309e-04],
        [-9.4243e-06,  3.7697e-05,  3.7697e-05,  ...,  1.8849e-05,
         -9.4243e-06, -1.1309e-04],
        [-9.4243e-06,  3.7697e-05,  3.7697e-05,  ...,  1.8849e-05,
         -9.4243e-06, -1.1309e-04]], device='cuda:0',
       grad_fn=<NativeBatchNormBackward0>)
x_t (torch.Size([12, 2])): tensor([[-0.0024,  0.0024],
        [-0.0024,  0.0024],
        [-0.0024,  0.0024],
        [-0.0024,  0.0024],
        [-0.0024,  0.0024],
        [-0.0024,  0.0024],
        [-0.0024,  0.0024],
        [-0.0024,  0.0024],
        [-0.0024,  0.0024],
        [-0.0024,  0.0024],
        [-0.0024,  0.0024],
        [-0.0024,  0.0024]], device='cuda:0',
       grad_fn=<NativeBatchNormBackward0>)
edge_attr (torch.Size([24000, 10])): tensor([[ 0.0000e+00,  4.7122e-06,  9.4243e-06,  ..., -1.8849e-05,
         -9.4243e-06,  0.0000e+00],
        [ 0.0000e+00,  4.7122e-06,  9.4243e-06,  ..., -1.8849e-05,
         -9.4243e-06,  0.0000e+00],
        [ 0.0000e+00,  4.7122e-06,  9.4243e-06,  ..., -1.8849e-05,
         -9.4243e-06,  0.0000e+00],
        ...,
        [ 0.0000e+00,  4.7122e-06,  9.4243e-06,  ..., -1.8849e-05,
         -9.4243e-06,  0.0000e+00],
        [ 0.0000e+00,  4.7122e-06,  9.4243e-06,  ..., -1.8849e-05,
         -9.4243e-06,  0.0000e+00],
        [ 0.0000e+00,  4.7122e-06,  9.4243e-06,  ..., -1.8849e-05,
         -9.4243e-06,  0.0000e+00]], device='cuda:0',
       grad_fn=<NativeBatchNormBackward0>)
u (torch.Size([1, 10])): tensor([[-5.5762,  0.5210,  0.8314, -0.9639, -1.9555, -6.9944,  1.3902, -3.0200,
          7.6311, -5.3591]], device='cuda:0', grad_fn=<AddmmBackward0>)
h (torch.Size([24000, 32]))
x_s[src] (torch.Size([24000, 10]))
x_t[tgt] (torch.Size([24000, 2]))
edge_attr (torch.Size([24000, 10]))
u[batch_e] torch.Size([24000, 10])

EDGE MODEL FORWARD
src (torch.Size([24000])): tensor([   0,    0,    0,  ..., 1999, 1999, 1999], device='cuda:0')
tgt (torch.Size([24000])): tensor([0, 1, 2,  ..., 7, 8, 9], device='cuda:0')
x_s (torch.Size([2000, 10])): tensor([[ 1.1309e-04, -1.8849e-04,  4.7122e-05,  ...,  2.3561e-05,
          0.0000e+00,  1.4726e-06],
        [ 1.1309e-04, -1.8849e-04,  4.7122e-05,  ...,  2.3561e-05,
          0.0000e+00,  1.4726e-06],
        [ 1.1309e-04, -1.8849e-04,  4.7122e-05,  ...,  2.3561e-05,
          0.0000e+00,  1.4726e-06],
        ...,
        [ 1.1309e-04, -1.8849e-04,  4.7122e-05,  ...,  2.3561e-05,
          0.0000e+00,  1.4726e-06],
        [ 1.1309e-04, -1.8849e-04,  4.7122e-05,  ...,  2.3561e-05,
          0.0000e+00,  1.4726e-06],
        [ 1.1309e-04, -1.8849e-04,  4.7122e-05,  ...,  2.3561e-05,
          0.0000e+00,  1.4726e-06]], device='cuda:0',
       grad_fn=<NativeBatchNormBackward0>)
x_t (torch.Size([12, 2])): tensor([[0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.],
        [0., 0.]], device='cuda:0', grad_fn=<NativeBatchNormBackward0>)
edge_attr (torch.Size([24000, 10])): tensor([[-2.3561e-06, -3.7697e-05, -3.7697e-05,  ...,  0.0000e+00,
          0.0000e+00,  3.7697e-05],
        [-2.3561e-06, -3.7697e-05, -3.7697e-05,  ...,  0.0000e+00,
          0.0000e+00,  3.7697e-05],
        [-2.3561e-06, -3.7697e-05, -3.7697e-05,  ...,  0.0000e+00,
          0.0000e+00,  3.7697e-05],
        ...,
        [-2.3561e-06, -3.7697e-05, -3.7697e-05,  ...,  0.0000e+00,
          0.0000e+00,  3.7697e-05],
        [-2.3561e-06, -3.7697e-05, -3.7697e-05,  ...,  0.0000e+00,
          0.0000e+00,  3.7697e-05],
        [-2.3561e-06, -3.7697e-05, -3.7697e-05,  ...,  0.0000e+00,
          0.0000e+00,  3.7697e-05]], device='cuda:0',
       grad_fn=<NativeBatchNormBackward0>)
u (torch.Size([1, 10])): tensor([[ 0.8506,  0.9978,  0.9570,  1.9675, -0.1312,  0.5897,  2.1660,  0.2699,
         -1.2706, -0.5004]], device='cuda:0', grad_fn=<AddmmBackward0>)
h (torch.Size([24000, 32]))
x_s[src] (torch.Size([24000, 10]))
x_t[tgt] (torch.Size([24000, 2]))
edge_attr (torch.Size([24000, 10]))
u[batch_e] torch.Size([24000, 10])
Traceback (most recent call last):
  File "/home/jl5824/pfs-neural-net/train.py", line 265, in <module>
    loss, gu, nu, ot, ut = Loss(time_pred, graph, penalty=penalty_pre, batchsize=batchsize)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jl5824/pfs-neural-net/train.py", line 27, in Loss
    x_g = graph.x_g
          ^^^^^^^^^
  File "/home/jl5824/.conda/envs/torch-gnn/lib/python3.12/site-packages/torch_geometric/data/data.py", line 561, in __getattr__
    return getattr(self._store, key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jl5824/.conda/envs/torch-gnn/lib/python3.12/site-packages/torch_geometric/data/storage.py", line 96, in __getattr__
    raise AttributeError(
AttributeError: 'GlobalStorage' object has no attribute 'x_g'

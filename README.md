# PFS Graph Neural Network

This project implements a Graph Neural Network (GNN) for processing bipartite graphs. Each graph represents the connectivity between fibers (source nodes) and galaxy classes (target nodes), where the model predicts discrete time values per edge using a differentiable rounding scheme. The code will run on CUDA, MPS, and CPU, though performance may vary.

## Project Structure

```
pfs-neural-net/
├── .gitignore
├── data/
│   └── utils.txt
├── graphs/
│   └── graph-0.pt
├── models/
│   ├── model_gnn_pre0.pth
│   └── model_gnn0.pth
├── README.md
├── slurm/
│   ├── adroit.md
│   ├── job.slurm
│   └── slurm-*******.out
└── source/
    ├── gnn.py
    ├── graph.py
    ├── params.py
    └── train.py
```

Roles of the relevant files: 

- **gnn.py** – Defines the GNN architecture, including custom layers and modules for edge, source, and target updates. See [`gnn.py`](source/gnn.py) for more details.
- **train.py** – Main training and evaluation loop. The file loads graphs from disk, executes pre-training and training loops, and saves model checkpoints. Refer to [`train.py`](source/train.py).
- **graph.py** – Constructs bipartite graphs from utility property data and saves them in the [`graphs/`](graphs/) directory. Check out [`graph.py`](source/graph.py).
- **params.py** – Contains parameters such as feature dimensions, number of fibers/classes, and device settings.
- **graphs/** – Directory with saved graph examples generated by [`graph.py`](source/graph.py).
- **slurm/** – SLURM job scripts and related documentation for running the code on systems with GPUs on Princeton's Adroit high-performance computing clusters. The existing script utilizes NVIDIA A100 GPUs. 
- **models/** – Saved checkpoint models to be loaded during training. 
- **utils.txt** – Utility file with additional parameters used in graph construction. Describes time required and number of galaxies per class. 

## Setup & Installation

1. **Clone the Repository**

    ```sh
    git clone https://github.com/joshua-lintropic/pfs-neural-net.git
    cd pfs-neural-net
    ```

2. **Create a Virtual Environment**

    ```sh
    python3 -m venv .venv
    source .venv/bin/activate
    ```

3. **Install PyTorch (CUDA or CPU)**

    You can replace `torch-2.7.0` with your installed PyTorch version and choose CPU or CUDA support. (For Apple silicon MPS, choose CPU installation). 

    ```sh
    pip install torch torchvision torchaudio
    pip install torch-geometric
    pip install torch-scatter -f https://data.pyg.org/whl/torch-2.7.0+cpu.html
    ```

    Optionally, you can also run `pip install -r requirements.txt` for CPU builds. 

## Running the Code

1. **Device Configuration**

    Choose your desired device (`cuda`, `mps`, or `cpu`) in [`params.py`](source/params.py). You can also modify other parameters for the neural network. 

2. **Graph Construction** 

    Execute [`graph.py`](source/graph.py) to build and save example complete (fully connected) bipartite graphs. This step converts utility property data from [`utils.txt`](source/utils.txt) into graphs saved in the [`graphs`](graphs/) folder. 

3. **Training the GNN**

    Run [`train.py`](source/train.py) to start training. To submit a SLURM job on a GPU-enabled cluster, use the provided job script in [`slurm/job.slurm`](slurm/job.slurm). 
